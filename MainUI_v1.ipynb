{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surabhi13gupta/ResumeSummarizer/blob/UI/MainUI_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "XAOlAmyZD_xz"
      },
      "outputs": [],
      "source": [
        "!pip -qq install langchain_openai\n",
        "!pip -qq install PyPDF2\n",
        "!pip -qq install langchain_community\n",
        "!pip -qq install faiss-gpu-cu11\n",
        "!pip -qq install streamlit pyngrok\n",
        "!pip -qq install streamlit_modal\n",
        "!pip -qq install PyMuPDF\n",
        "!pip -qq install python-docx\n",
        "!pip -qq install docx2pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0mjn-Ef16PG",
        "outputId": "6b2fbc26-c68d-491f-e23e-46be31d7c86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "mAg4hFoVEebB"
      },
      "outputs": [],
      "source": [
        "with open(\".env\", \"w\") as f:\n",
        "    from google.colab import userdata\n",
        "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "    f.write(f\"GITHUB_TOKEN={GITHUB_TOKEN}\\n\")\n",
        "\n",
        "    ngrok_key = userdata.get('NGROK_KEY')\n",
        "    f.write(f'ngrok_token={ngrok_key}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSFvzyeSU4qB",
        "outputId": "f3040743-0d51-4885-b171-5382e2cc0e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import os\n",
        "ngrok_token = os.getenv(\"ngrok_token\")\n",
        "!ngrok config add-authtoken {ngrok_token}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSZOhWyNDupb",
        "outputId": "8dc18d03-5890-45ca-d951-5c7dd13f8313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting resume_uploader.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile resume_uploader.py\n",
        "import zipfile\n",
        "import os\n",
        "import tempfile\n",
        "from PyPDF2 import PdfReader\n",
        "import docx\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CDS-B9-Group11/Capstone Project/Codes/')\n",
        "from masker import redact_personal_information\n",
        "\n",
        "def extract_text_from_pdf(file):\n",
        "    reader = PdfReader(file)\n",
        "    return \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
        "\n",
        "def extract_text_from_docx(file):\n",
        "    doc = docx.Document(file)\n",
        "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "def extract_from_zip(zip_file):\n",
        "    extracted_texts = []\n",
        "    with zipfile.ZipFile(zip_file) as z:\n",
        "        for name in z.namelist():\n",
        "            ext = name.rsplit('.', 1)[-1].lower()\n",
        "            with z.open(name) as f:\n",
        "                if ext == \"pdf\":\n",
        "                    modified_pdf = redact_personal_information(f)\n",
        "                    extracted_texts.append(modified_pdf(f))\n",
        "                elif ext == \"docx\":\n",
        "                    extracted_texts.append(extract_text_from_docx(f))\n",
        "    return extracted_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H8Slv3u9ku_",
        "outputId": "637049b5-e8ee-435e-ccb3-99b2a3788ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CDS-B9-Group11/Capstone Project/Codes/')\n",
        "\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from google.colab import userdata\n",
        "from datetime import datetime\n",
        "import os\n",
        "from streamlit_modal import Modal\n",
        "from io import BytesIO\n",
        "from resume_uploader import extract_text_from_pdf, extract_text_from_docx, extract_from_zip\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from masker import redact_personal_information\n",
        "import pandas as pd\n",
        "from langchain_core.runnables import RunnableSequence\n",
        "\n",
        "load_dotenv()\n",
        "github_token = os.getenv(\"GITHUB_TOKEN\")\n",
        "endpoint = \"https://models.github.ai/inference\"\n",
        "model_name = \"openai/gpt-4.1-nano\"\n",
        "\n",
        "def get_text_chunks(text):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 10000,\n",
        "    chunk_overlap = 100\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks\n",
        "\n",
        "def get_vector_store(text_chunks):\n",
        "    embeddings = OpenAIEmbeddings(\n",
        "        model='text-embedding-3-small',\n",
        "        dimensions=1536,\n",
        "        base_url = endpoint,\n",
        "        api_key= github_token)\n",
        "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
        "    vector_store.save_local(\"faiss_index\")\n",
        "\n",
        "def get_conversation_chain():\n",
        "    model = ChatOpenAI(\n",
        "    base_url = endpoint,\n",
        "    api_key= github_token,\n",
        "    model=model_name,\n",
        "    temperature=0.1\n",
        "    )\n",
        "    chat_prompt_template = ChatPromptTemplate([\n",
        "         ('system', 'You are good resume parser expert and helps in answering questions. Answer the question from the provided resume. Make sure to provide all the details, if the answer is not in the provided resume just reply back, \"Answer is not available in provided resume\", dont provide the wrong answers or dont hallucinate the answers.\\n Resume: \\n {resume}?'),\n",
        "         ('human', 'Question: \\n {question}\\nAnswer:')\n",
        "        ])\n",
        "    chain = chat_prompt_template|model|StrOutputParser()\n",
        "    return chain\n",
        "\n",
        "def resume_summarization(resume_text):\n",
        "    template = '''Generate a Resume Summary Script in 5-6 bullet points for an engaging video presentation aimed at a hiring manager.\n",
        "            - Tone: Friendly, Confident, Assertive.\n",
        "            - Base the script strictly on the given resume content ‚Äî do not hallucinate or add unverifiable details.:\\n {resume}'''\n",
        "\n",
        "    prompt = PromptTemplate(input_variables=['resume'],template=template)\n",
        "    output_parser = StrOutputParser()\n",
        "    model = ChatOpenAI(\n",
        "        base_url = endpoint,\n",
        "        api_key= github_token,\n",
        "        model=model_name,\n",
        "        temperature=0.1\n",
        "        )\n",
        "    chain = RunnableSequence(prompt, model, output_parser)\n",
        "\n",
        "    summarised_text = chain.invoke({'resume': resume_text})\n",
        "\n",
        "    return summarised_text\n",
        "\n",
        "def notice_period_prompt():\n",
        "    model = ChatOpenAI(\n",
        "    base_url = endpoint,\n",
        "    api_key= github_token,\n",
        "    model=model_name,\n",
        "    temperature=0.1\n",
        "    )\n",
        "    chat_prompt_template = ChatPromptTemplate([\n",
        "         ('system', 'You are good and helpful assistant and helps in answering questions. Find out the notice period from public available sources for most recent organization provided in resume. Make sure to provide to provide accurate details and provide the source link at the end of answer, dont provide the wrong answers or dont hallucinate the answers. \\n Resume: \\n {resume}?'),\n",
        "         ('human', 'Question: \\n Notice Period of the most recent job organization the candidate working for. \\nAnswer:')\n",
        "        ])\n",
        "    chain = chat_prompt_template|model|StrOutputParser()\n",
        "    return chain\n",
        "\n",
        "def handle_notice_period():\n",
        "    user_question = \"Notice Period of the most recent job organization the candidate working for\"\n",
        "    embeddings = OpenAIEmbeddings(\n",
        "        model='text-embedding-3-small',\n",
        "        dimensions=1536,\n",
        "        base_url = endpoint,\n",
        "        api_key= github_token,)\n",
        "    new_db = FAISS.load_local(\"faiss_index\", embeddings=embeddings, allow_dangerous_deserialization=True)\n",
        "    docs = new_db.similarity_search(user_question)\n",
        "    chain = notice_period_prompt()\n",
        "    response = chain.invoke({\n",
        "        \"resume\": docs\n",
        "    })\n",
        "    return response\n",
        "\n",
        "def handle_user_input(user_question):\n",
        "    embeddings = OpenAIEmbeddings(\n",
        "        model='text-embedding-3-small',\n",
        "        dimensions=1536,\n",
        "        base_url = endpoint,\n",
        "        api_key= github_token,)\n",
        "    new_db = FAISS.load_local(\"faiss_index\", embeddings=embeddings, allow_dangerous_deserialization=True)\n",
        "    docs = new_db.similarity_search(user_question)\n",
        "    chain = get_conversation_chain()\n",
        "    response = chain.invoke({\n",
        "        \"resume\": docs,\n",
        "        \"question\": user_question\n",
        "    })\n",
        "    return response\n",
        "\n",
        "def build_resume_df():\n",
        "    df = pd.DataFrame(columns=['Rank', 'Resume', 'Score', 'Content'])\n",
        "    return df\n",
        "\n",
        "resume_summary_content = None\n",
        "\n",
        "st.set_page_config(\"Pre-Screening Intelligence: TalAI\", layout=\"wide\")\n",
        "resume_modal = Modal(\"üìÇ Resume Tools\", key=\"resume-tools-modal\", max_width=\"1000px\")\n",
        "\n",
        "section_list = [\n",
        "    'Work Experience',\n",
        "    'Education',\n",
        "    'Skills',\n",
        "    'Academic Projects',\n",
        "    'Certification, Award & Recognition',\n",
        "    'Career Objectives or Summary'\n",
        "]\n",
        "\n",
        "# --- Initialize session state ---\n",
        "if \"resume_df\" not in st.session_state:\n",
        "    st.session_state.resume_df = pd.DataFrame(columns=[\"Rank\", \"Resume\", \"Score\", \"Content\"])\n",
        "if \"show_modal\" not in st.session_state:\n",
        "    st.session_state.show_modal = True\n",
        "if \"close_modal\" not in st.session_state:\n",
        "    st.session_state.close_modal = False\n",
        "if \"selected_index\" not in st.session_state:\n",
        "    st.session_state.selected_index = None\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history\n",
        "\n",
        "\n",
        "if \"resume_df\" not in st.session_state:\n",
        "    st.session_state.resume_df = build_resume_df()\n",
        "df = st.session_state.resume_df\n",
        "\n",
        "# Initialize once\n",
        "if \"show_modal\" not in st.session_state:\n",
        "    st.session_state.show_modal = False\n",
        "\n",
        "# Inject custom CSS to reduce top padding and fix sticky layout\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "        /* Reduce top padding for the whole app */\n",
        "        .block-container {\n",
        "            padding-top: 0.8rem;\n",
        "        }\n",
        "\n",
        "        /* Sticky button container styling */\n",
        "        .sticky-buttons {\n",
        "            position: sticky;\n",
        "            top: 0;\n",
        "            background-color: white;\n",
        "            padding: 0.6rem 0.5rem;\n",
        "            z-index: 999;\n",
        "            border-bottom: 1px solid #ddd;\n",
        "        }\n",
        "\n",
        "        /* Ensure buttons don't get clipped */\n",
        "        .element-container button {\n",
        "            margin-bottom: 0 !important;\n",
        "        }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "with st.container():\n",
        "    st.markdown('<div class=\"sticky-buttons\">', unsafe_allow_html=True)\n",
        "    top_left, top_right = st.columns([1, 1])\n",
        "    with top_left:\n",
        "        if st.button(\"üì§ Upload Resumes\"):\n",
        "            st.session_state.show_modal = True\n",
        "    with top_right:\n",
        "        if st.button(\"üóëÔ∏è Clear Resumes\"):\n",
        "            st.session_state.resume_df = build_resume_df()\n",
        "    st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "if st.session_state.show_modal:\n",
        "    with st.expander(\"Upload Modal\", expanded=st.session_state.show_modal):\n",
        "        st.markdown(\"\"\"\n",
        "        <div style=\"display: flex; flex-direction: column; align-items: center; text-align: center;\">\n",
        "        <img src=\"https://raw.githubusercontent.com/surabhi13gupta/LangChains/main/TalAI.png\" width=\"60\" style=\"border-radius: 50%; margin-bottom: 1rem;\">\n",
        "        <h4 style=\"margin-bottom: 0;\">TalAI ResumeTools</h4>\n",
        "        <p style=\"margin-top: 0;\">Upload your resume to extract insights, skills, and suggestions.</p>\n",
        "        </div>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        uploaded_files = st.file_uploader(\n",
        "            \"Upload Resumes (PDF, DOCX, ZIP allowed)\",\n",
        "            type=[\"pdf\", \"docx\", \"zip\"],\n",
        "            accept_multiple_files=True\n",
        "        )\n",
        "\n",
        "        stream = st.selectbox(\n",
        "            \"Select your Domain:\",\n",
        "            [\"Information Technology\", \"Finance\", \"Human Resources\", \"Sales\", \"Legal/Advocate\", \"Engineering\"]\n",
        "        )\n",
        "\n",
        "        if st.button(\"Submit and Process\") and uploaded_files:\n",
        "            with st.spinner(\"Processing...\"):\n",
        "                rank = 1\n",
        "                for uploaded_file in uploaded_files:\n",
        "                    all_texts = []\n",
        "                    ext = uploaded_file.name.rsplit('.', 1)[-1].lower()\n",
        "                    if ext == \"pdf\":\n",
        "                        modified_pdf = redact_personal_information(uploaded_file)\n",
        "                        all_texts.append(extract_text_from_pdf(modified_pdf))\n",
        "                    elif ext == \"docx\":\n",
        "                        all_texts.append(extract_text_from_docx(uploaded_file))\n",
        "                    elif ext == \"zip\":\n",
        "                        zip_bytes = BytesIO(uploaded_file.read())\n",
        "                        all_texts.extend(extract_from_zip(zip_bytes))\n",
        "                    st.session_state.resume_df.loc[len(st.session_state.resume_df)] = [rank, uploaded_file.name, 10, all_texts]\n",
        "                    rank += 1\n",
        "\n",
        "                st.success(\"Resumes uploaded and processed!\")\n",
        "                st.session_state.chat_history = []\n",
        "\n",
        "    # Close button outside expander\n",
        "    if st.button(\"‚úÖ Close\"):\n",
        "        st.session_state.close_modal = True\n",
        "\n",
        "        #         if st.button(\"‚úÖ Close\"):\n",
        "        #             st.session_state.show_modal = False\n",
        "        #             st.experimental_rerun()\n",
        "        # else:\n",
        "        #     st.info(\"Awaiting file upload...\")\n",
        "\n",
        "# Handle modal close early\n",
        "if st.session_state.get(\"close_modal\", False):\n",
        "    st.session_state.show_modal = False\n",
        "    st.session_state.close_modal = False\n",
        "    st.rerun()\n",
        "\n",
        "left_col, middle_col, right_col = st.columns([1, 1, 1])\n",
        "\n",
        "with left_col:\n",
        "    st.subheader(\"üßë‚Äçüíº Recruiters Input Dashboard\")\n",
        "\n",
        "    # Job description input\n",
        "    job_description = st.text_area(\n",
        "        \"üìù Job Description\",\n",
        "        height=200,\n",
        "        placeholder=\"Paste the job role or requirements here...\"\n",
        "    )\n",
        "\n",
        "    for section in section_list:\n",
        "        with st.expander(f\"üìÇ {section}\"):\n",
        "            st.text_area(f\"‚úèÔ∏è Edit or review: {section}\", height=150, placeholder=f\"Enter details for {section}...\")\n",
        "\n",
        "    # Submit button\n",
        "    if st.button(\"üöÄ Match Resumes\") and job_description:\n",
        "        with st.spinner(\"Matching resumes...\"):\n",
        "            # Placeholder for vector search logic\n",
        "            top_matches = [\n",
        "                \"**1. Jane Doe** ‚Äî ML Engineer, 5 yrs exp, NLP-heavy projects\",\n",
        "                \"**2. Ravi Kumar** ‚Äî Time Series Specialist, fintech background\",\n",
        "                \"**3. Aisha Rahman** ‚Äî GenAI pipeline builder, LangChain expert\",\n",
        "                \"**4. Leo Zhang** ‚Äî Resume parsing wizard, UX-focused\",\n",
        "                \"**5. Sara Ali** ‚Äî Dashboard designer, Streamlit + LLM integration\"\n",
        "            ]\n",
        "\n",
        "            # Display results\n",
        "            st.markdown(\"### üèÜ Top Resume Matches\")\n",
        "            for match in top_matches:\n",
        "                st.markdown(f\"- {match}\")\n",
        "\n",
        "with middle_col:\n",
        "    # First Section: Table Placeholder\n",
        "    st.subheader(\"üìä Top 5 Resumes Rank Table\")\n",
        "    # st.markdown(\"### üìã Resume Rank Table\")\n",
        "    st.write(\"Table content goes here...\")\n",
        "    # Track selected rows\n",
        "    selected_rows = []\n",
        "\n",
        "    # Initialize session state variable\n",
        "    if \"selected_index\" not in st.session_state:\n",
        "        st.session_state.selected_index = None\n",
        "\n",
        "    # Display each row with a checkbox\n",
        "    for i in range(len(df)):\n",
        "        cols = st.columns([1, 1, 1, 1])  # Adjust column widths\n",
        "        cols[0].write(df.loc[i, \"Rank\"])\n",
        "        cols[1].write(df.loc[i, \"Resume\"])\n",
        "        cols[2].write(df.loc[i, \"Score\"])\n",
        "\n",
        "        # Checkbox reflects whether this row is selected\n",
        "        selected = cols[3].checkbox(\n",
        "            \"Review\",\n",
        "            key=f\"select_{i}\",\n",
        "            value=(st.session_state.selected_index == i),\n",
        "            on_change=lambda idx=i: st.session_state.update({\"selected_index\": idx})\n",
        "        )\n",
        "\n",
        "        # Append only the selected row\n",
        "        if st.session_state.selected_index == i:\n",
        "            selected_rows.append(df.loc[i])\n",
        "\n",
        "    # Display each row with a checkbox\n",
        "\n",
        "    # for i in range(len(df)):\n",
        "    #     cols = st.columns([1, 1, 1, 1])  # Adjust column widths\n",
        "    #     cols[0].write(df.loc[i, \"Rank\"])\n",
        "    #     cols[1].write(df.loc[i, \"Resume\"])\n",
        "    #     cols[2].write(df.loc[i, \"Score\"])\n",
        "    #     selected = cols[3].checkbox(\"Review\", key=f\"select_{i}\")\n",
        "    #     if selected:\n",
        "    #         selected_rows.append(df.loc[i])\n",
        "\n",
        "    # selected_df = pd.DataFrame(selected_rows, columns=[\"Rank\", \"Resume\", \"Score\", \"Review\"])\n",
        "\n",
        "    # Show selected rows\n",
        "    if selected_rows:\n",
        "        st.markdown(\"### Selected Resume for Review:\")\n",
        "        resume_id = selected_rows[0][1]\n",
        "        resume_content = df.loc[df.Resume == resume_id, 'Content'].values[0]\n",
        "        st.write(resume_id)\n",
        "        resume_summary_content = resume_summarization(resume_content)\n",
        "        combined_text = \"\\n\\n\".join(resume_content)\n",
        "        text_chunks = get_text_chunks(combined_text)\n",
        "        get_vector_store(text_chunks)\n",
        "    else:\n",
        "        resume_summary_content = None\n",
        "\n",
        "    # Divider (optional)\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Second Section: Text Summarization\n",
        "    st.subheader(\"üìù Summarization Dashboard\")\n",
        "    if resume_summary_content is None:\n",
        "        st.markdown(\"Summary section - This is your selected resume summary...\")\n",
        "    else:\n",
        "        st.markdown(resume_summary_content)\n",
        "\n",
        "with right_col:\n",
        "    st.markdown(\"### üé• Video Summary\")\n",
        "    st.button(\"Summarize Video\")\n",
        "    st.write(\"Video summary will appear here.\")\n",
        "\n",
        "    # Divider (optional)\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Chat popover inside right column\n",
        "    with st.popover(\"üí¨ Chat with TalAI\", icon=\":material/chat:\", width=\"content\"):\n",
        "        st.header(\"üí¨ Chat with TalAI\")\n",
        "\n",
        "        # # Initialize chat history and flag\n",
        "        # if \"chat_history\" not in st.session_state:\n",
        "        #     st.session_state.chat_history = []\n",
        "\n",
        "        # if \"first_question_sent\" not in st.session_state:\n",
        "        #     st.session_state.first_question_sent = False\n",
        "\n",
        "        # # Send first question only once\n",
        "        # if not st.session_state.first_question_sent:\n",
        "        #     first_question = \"Candidate Name, total years of experience and recent job organisation\"\n",
        "        #     st.session_state.chat_history.append({\n",
        "        #         \"role\": \"user\",\n",
        "        #         \"content\": first_question\n",
        "        #     })\n",
        "        #     recent_job = handle_user_input(first_question)\n",
        "        #     st.session_state.chat_history.append({\n",
        "        #         \"role\": \"assistant\",\n",
        "        #         \"content\": recent_job\n",
        "        #     })\n",
        "        #     st.session_state.first_question_sent = True  # Prevent future duplication\n",
        "\n",
        "        # # Handle user input\n",
        "        # user_question = st.chat_input(\"Ask TalAI about the selected resume...\")\n",
        "        # if user_question:\n",
        "        #     st.session_state.chat_history.append({\n",
        "        #         \"role\": \"user\",\n",
        "        #         \"content\": user_question\n",
        "        #     })\n",
        "        #     response = handle_user_input(user_question)\n",
        "        #     st.session_state.chat_history.append({\n",
        "        #         \"role\": \"assistant\",\n",
        "        #         \"content\": response\n",
        "        #     })\n",
        "        # chat_container = st.container()\n",
        "        # # Render all messages inside chat_container\n",
        "        # with chat_container:\n",
        "        #     for msg in st.session_state.chat_history:\n",
        "        #         role = msg[\"role\"]\n",
        "        #         prefix = \"You: \" if role == \"user\" else \"TalAI: \"\n",
        "        #         st.chat_message(role).write(prefix + msg[\"content\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if \"chat_history\" not in st.session_state:\n",
        "            st.session_state.chat_history = []\n",
        "\n",
        "        for msg in st.session_state.chat_history:\n",
        "            role = \"user\" if msg[\"role\"] == \"user\" else \"assistant\"\n",
        "            st.chat_message(role).write(msg[\"content\"])\n",
        "\n",
        "        chat_container = st.container()\n",
        "\n",
        "        if resume_summary_content:\n",
        "            if \"first_question_sent\" not in st.session_state:\n",
        "                st.session_state.first_question_sent = False\n",
        "\n",
        "            if not st.session_state.first_question_sent:\n",
        "                # Handle input first\n",
        "                first_question = \"Candidate Name, total years of experience and recent job organisation\"\n",
        "                st.session_state.chat_history.append({\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": first_question\n",
        "                    })\n",
        "                recent_job = handle_user_input(first_question)\n",
        "                st.session_state.chat_history.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": recent_job\n",
        "                })\n",
        "                st.session_state.first_question_sent = True\n",
        "\n",
        "            user_question = st.chat_input(\"Ask TalAI about the selected resume...\")\n",
        "            if user_question:\n",
        "                st.session_state.chat_history.append({\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": user_question\n",
        "                })\n",
        "                response = handle_user_input(user_question)\n",
        "                st.session_state.chat_history.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": response\n",
        "                })\n",
        "\n",
        "            # Render all messages inside chat_container\n",
        "            with chat_container:\n",
        "                for msg in (st.session_state.chat_history):  # Latest at top\n",
        "                    role = \"user\" if msg[\"role\"] == \"user\" else \"assistant\"\n",
        "                    prefix = \"You: \" if role == \"user\" else \"TalAI: \"\n",
        "                    st.chat_message(role).write(prefix + msg[\"content\"])\n",
        "\n",
        "\n",
        "# with right_col:\n",
        "#     st.header(\"üí¨ Chat with TalAI\")\n",
        "#     if \"chat_history\" not in st.session_state:\n",
        "#         st.session_state.chat_history = []\n",
        "\n",
        "#     for msg in st.session_state.chat_history:\n",
        "#         role = \"user\" if msg[\"role\"] == \"user\" else \"assistant\"\n",
        "#         st.chat_message(role).write(msg[\"content\"])\n",
        "\n",
        "#     chat_container = st.container()\n",
        "\n",
        "    # # Handle input first\n",
        "    # first_question = \"Candidate Name, total years of experience and recent job organisation\"\n",
        "    # st.session_state.chat_history.append({\n",
        "    #         \"role\": \"user\",\n",
        "    #         \"content\": first_question\n",
        "    #     })\n",
        "    # recent_job = handle_user_input(first_question)\n",
        "    # st.session_state.chat_history.append({\n",
        "    #     \"role\": \"assistant\",\n",
        "    #     \"content\": recent_job\n",
        "    # })\n",
        "\n",
        "    # st.session_state.chat_history.append({\n",
        "    #         \"role\": \"user\",\n",
        "    #         \"content\": \"Notice Period information for recent company\"\n",
        "    #     })\n",
        "    # notice_response = handle_notice_period()\n",
        "    # st.session_state.chat_history.append({\n",
        "    #     \"role\": \"assistant\",\n",
        "    #     \"content\": notice_response\n",
        "    # })\n",
        "\n",
        "    # user_question = st.chat_input(\"Ask TalAI about the selected resume...\")\n",
        "    # if user_question:\n",
        "    #     st.session_state.chat_history.append({\n",
        "    #         \"role\": \"user\",\n",
        "    #         \"content\": user_question\n",
        "    #     })\n",
        "    #     response = handle_user_input(user_question)\n",
        "    #     st.session_state.chat_history.append({\n",
        "    #         \"role\": \"assistant\",\n",
        "    #         \"content\": response\n",
        "    #     })\n",
        "\n",
        "    # # Render all messages inside chat_container\n",
        "    # with chat_container:\n",
        "    #     for msg in (st.session_state.chat_history):  # Latest at top\n",
        "    #         role = \"user\" if msg[\"role\"] == \"user\" else \"assistant\"\n",
        "    #         prefix = \"You: \" if role == \"user\" else \"TalAI: \"\n",
        "    #         st.chat_message(role).write(prefix + msg[\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rPY3Nlx9q4W",
        "outputId": "f18073c0-9185-4cca-88a9-6c392d64385e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit URL: NgrokTunnel: \"https://c3bd28c5eaaf.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "public_url = ngrok.connect(addr=8501)\n",
        "\n",
        "print(f\"Streamlit URL: {public_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olrmCFD89wyA",
        "outputId": "a3913439-0f72-4034-f36a-9d966c6c6f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.73.172.30:8501\u001b[0m\n",
            "\u001b[0m\n",
            "Enter\n",
            "Enter\n",
            "/content/main.py:323: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  resume_id = selected_rows[0][1]\n",
            "/content/main.py:323: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  resume_id = selected_rows[0][1]\n",
            "/content/main.py:323: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  resume_id = selected_rows[0][1]\n",
            "/content/main.py:323: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  resume_id = selected_rows[0][1]\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run main.py&"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqByR5QOhLg9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4j0hjhqS9xF0ra6r/MeYm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}